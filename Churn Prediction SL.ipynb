{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello, my name is Artem. I'm going to review your project!\n",
    "\n",
    "You can find my comments in <font color='green'>green</font>, <font color='blue'>blue</font> or <font color='red'>red</font> boxes like this:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> if everything is done succesfully\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Improve: </b> \"Improve\" comments mean that there are tiny corrections that could help you to make your project better.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Needs fixing:</b> if the block requires some corrections. Work can't be accepted with the red comments.\n",
    "</div>\n",
    "\n",
    "### <font color='orange'>General feedback</font>\n",
    "* You've worked really hard and submitted a solid project.\n",
    "* Thank you for structuring the project. It's a pleasure to check such notebooks.\n",
    "* There is one thing that need to be done before your project is complete, but it's pretty straightforward.\n",
    "* There are few things I'd like you to check. They're not mistakes, but your project could be improved if you correct them.\n",
    "* While there's room for improvement, on the whole, your project is looking good.\n",
    "* I believe you can easily fix it! Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>General feedback (review 2)</font>\n",
    "* All your hard work has paid off, and now your project is perfect!\n",
    "* Keep up the good work. Good luck next!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project description\n",
    "\n",
    "Beta Bank customers are leaving: little by little, chipping away every month.\n",
    "\n",
    "The bankers figured out it’s cheaper to save the existing customers rather than\n",
    "to attract new ones.\n",
    "\n",
    "We need to predict whether a customer will leave the bank soon. You have the\n",
    "data on clients’ past behavior and termination of contracts with the bank.\n",
    "\n",
    "Build a model with the maximum possible F1 score. \n",
    "To pass the project, you need an F1 score of at least 0.59. Check the F1 for the test set.\n",
    "\n",
    "Additionally, measure the AUC-ROC metric and compare it with the F1.\n",
    "\n",
    "Data source: https://www.kaggle.com/barelydedicated/bank-customer-churnmodeling{target=\"blank\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "The data can be found in '/datasets/Churn.csv' file. Download the dataset.\n",
    "\n",
    "**Features:**\n",
    "\n",
    "`RowNumber` — data string index\n",
    "\n",
    "`CustomerId` — unique customer identifier\n",
    "\n",
    "`Surname` — surname\n",
    "\n",
    "`CreditScore` — credit score\n",
    "\n",
    "`Geography` — country of residence\n",
    "\n",
    "`Gender` — gender\n",
    "\n",
    "`Age` — age\n",
    "\n",
    "`Tenure` — period of maturation for a customer’s fixed deposit (years)\n",
    "\n",
    "`Balance` — account balance\n",
    "\n",
    "`NumOfProducts` — number of banking products used by the customer\n",
    "\n",
    "`HasCrCard` — customer has a credit card\n",
    "\n",
    "`IsActiveMember` — customer’s activeness\n",
    "\n",
    "`EstimatedSalary` — estimated salary\n",
    "\n",
    "**Target**\n",
    "\n",
    "`Exited` — сustomer has left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ol>\n",
    "      <li><a href=\"#1\">Download and prepare the data</a></li>\n",
    "      <li><a href=\"#2\">Examine the balance of classes</a></li>\n",
    "      <li><a href=\"#3\">Improve the quality of the model</a></li>\n",
    "      <li><a href=\"#4\">Perform the final testing</a></li>\n",
    "      <li><a href=\"#5\">Overall conclusion</a></li>\n",
    "    </ol> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"1\">Download and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas and numpy for data preprocessing and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# seaborn for visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# import train_test_split to split data\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "pd.options.mode.chained_assignment = None # to avoid SettingWithCopyWarning after scaling\n",
    "\n",
    "# import machine learning module from the sklearn library\n",
    "from sklearn.dummy import DummyClassifier # import dummy classifier\n",
    "from sklearn.tree import DecisionTreeClassifier # import decision tree classifier\n",
    "from sklearn.linear_model import LogisticRegression # import logistic regression \n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest algorithm\n",
    "from catboost import CatBoostClassifier\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "# import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import sklearn utilities\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> Thank you for collecting all imports in the first cell!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check na percent within the data\n",
    "def get_percent_of_na(df, num):\n",
    "    count = 0\n",
    "    df = df.copy()\n",
    "    s = (df.isna().sum() / df.shape[0])\n",
    "    for column, percent in zip(s.index, s.values):\n",
    "        num_of_nulls = df[column].isna().sum()\n",
    "        if num_of_nulls == 0:\n",
    "            continue\n",
    "        else:\n",
    "            count += 1\n",
    "        print('Column {} has {:.{}%} percent of Nulls, and {} of nulls'.format(column, percent, num, num_of_nulls))\n",
    "    if count != 0:\n",
    "        print(\"\\033[1m\" + 'There are {} columns with NA.'.format(count) + \"\\033[0m\")\n",
    "    else:\n",
    "        print()\n",
    "        print(\"\\033[1m\" + 'There are no columns with NA.' + \"\\033[0m\")\n",
    "        \n",
    "# function to display general information about the dataset\n",
    "def get_info(df):\n",
    "    \"\"\"\n",
    "    This function uses the head(), info(), describe(), shape() and duplicated() \n",
    "    methods to display the general information about the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\033[1m\" + '-'*100 + \"\\033[0m\")\n",
    "    print('Head:')\n",
    "    print()\n",
    "    display(df.head())\n",
    "    print('-'*100)\n",
    "    print('Info:')\n",
    "    print()\n",
    "    display(df.info())\n",
    "    print('-'*100)\n",
    "    print('Describe:')\n",
    "    print()\n",
    "    display(df.describe())\n",
    "    print('-'*100)\n",
    "    display(df.describe(include='object'))\n",
    "    print()\n",
    "    print('Columns with nulls:')\n",
    "    display(get_percent_of_na(df, 4))  # check this out\n",
    "    print('-'*100)\n",
    "    print('Shape:')\n",
    "    print(df.shape)\n",
    "    print('-'*100)\n",
    "    print('Duplicated:')\n",
    "    print(\"\\033[1m\" + 'We have {} duplicated rows.\\n'.format(df.duplicated().sum()) + \"\\033[0m\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the general infos about the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "Head:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Describe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surname</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>2932</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>Smith</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>32</td>\n",
       "      <td>5014</td>\n",
       "      <td>5457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Surname Geography Gender\n",
       "count    10000     10000  10000\n",
       "unique    2932         3      2\n",
       "top      Smith    France   Male\n",
       "freq        32      5014   5457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with nulls:\n",
      "Column Tenure has 9.0900% percent of Nulls, and 909 of nulls\n",
      "\u001b[1mThere are 1 columns with NA.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Shape:\n",
      "(10000, 14)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Duplicated:\n",
      "\u001b[1mWe have 0 duplicated rows.\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the general infos we conclude that:\n",
    "- our dataframe is composed of 10000 rows and 14 columns\n",
    "- Missing data are MAR \n",
    "- with a 9.99% of missings in `Tenure` column\n",
    "- since the missing percent is less than 10%, we can drop it, or we can replace the nas with the mean, we'll see, but "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> Data loading and initial analysis were done well!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tenure column**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We get unique values of `Surname` in order to get the specific `Tenure` for those unique names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in the Tenure column\n",
    "# get unique values of name from this dataframe\n",
    "for surname in df['Surname'].unique().tolist():\n",
    "    # get specific 'Surname' possible Tenure\n",
    "    specific_surname_df = df[df['Surname'] == surname].dropna()['Tenure']\n",
    "    surname_tenure_list = specific_surname_df.unique().tolist()\n",
    "    # for the missing values, assign a random choice of the tenure for that surname. The default is the median of the 'Tenure'\n",
    "    if surname_tenure_list != []:\n",
    "        df.loc[(df['Surname'] == surname) & (df['Tenure'] != df['Tenure']), 'Tenure'] = random.choice(surname_tenure_list)\n",
    "    else:\n",
    "        df.loc[(df['Surname'] == surname) & (df['Tenure'] != df['Tenure']), 'Tenure'] = df['Tenure'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.008400</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.871333</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.008400   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.871333   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Improve: </b> It's better not to use random for filling nans. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert data to the correct data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_type(df, cols, type_val):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(type_val)\n",
    "        \n",
    "convert_to_type(df, ['Surname', 'Geography', 'Gender'], str)\n",
    "convert_to_type(df, ['RowNumber', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'Exited'], 'int64')\n",
    "convert_to_type(df, ['Balance', 'EstimatedSalary'], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "- We've replaced missing values, \n",
    "- changed dataypes\n",
    "- the data seems clean now, we can proceed to feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For features we will use:\n",
    "- One-Hot-Encoding for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some features are useless for our predictions and analysis, we will drop them, like `CustomerId`, `Surname` and `RowNumber`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['CustomerId', 'RowNumber', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> I agree that we don't need these columns.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OHE**: one-hot encoding of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(df, drop_first=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declare features and target variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_ohe['Exited']\n",
    "features = df_ohe.drop(['Exited'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> The data was encoded in the right way!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data into training and testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set now contains 7000 observations representing 70% of the data\n",
      "The test set now contains 3000 observations representing 30% of the data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.30, random_state=12345\n",
    ")\n",
    "\n",
    "# display the shape of the split dataset\n",
    "print('The train set now contains {}'.format(features_train.shape[0]) + ' observations representing 70% of the data')\n",
    "print('The test set now contains {}'.format(features_test.shape[0]) + ' observations representing 30% of the data')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of features and target\u001b[0m\n",
      "------------------------------\n",
      "Train features : (7000, 11)\n",
      "Train target   : (7000,)\n",
      "Test features  : (3000, 11)\n",
      "Test target    : (3000,)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9716</td>\n",
       "      <td>1.658077</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>-0.013195</td>\n",
       "      <td>0.635477</td>\n",
       "      <td>2.527132</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>0.955284</td>\n",
       "      <td>1.480907</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.198643</td>\n",
       "      <td>0.584111</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>0.375870</td>\n",
       "      <td>-0.895510</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>0.955284</td>\n",
       "      <td>0.153167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589</td>\n",
       "      <td>-1.374648</td>\n",
       "      <td>0.774530</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>1.302947</td>\n",
       "      <td>0.815811</td>\n",
       "      <td>-1.549099</td>\n",
       "      <td>-1.046809</td>\n",
       "      <td>0.817773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7507</td>\n",
       "      <td>-0.784664</td>\n",
       "      <td>0.488901</td>\n",
       "      <td>1.386252</td>\n",
       "      <td>0.696496</td>\n",
       "      <td>-0.895510</td>\n",
       "      <td>0.645536</td>\n",
       "      <td>-1.046809</td>\n",
       "      <td>0.329403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1457</td>\n",
       "      <td>2.051400</td>\n",
       "      <td>2.583513</td>\n",
       "      <td>-0.363056</td>\n",
       "      <td>-1.222967</td>\n",
       "      <td>0.815811</td>\n",
       "      <td>-1.549099</td>\n",
       "      <td>0.955284</td>\n",
       "      <td>-0.617269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "9716     1.658077  0.012853 -0.013195  0.635477       2.527132   0.645536   \n",
       "224      0.198643  0.584111  0.336667  0.375870      -0.895510   0.645536   \n",
       "589     -1.374648  0.774530  0.336667  1.302947       0.815811  -1.549099   \n",
       "7507    -0.784664  0.488901  1.386252  0.696496      -0.895510   0.645536   \n",
       "1457     2.051400  2.583513 -0.363056 -1.222967       0.815811  -1.549099   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "9716        0.955284         1.480907                  1                0   \n",
       "224         0.955284         0.153167                  1                0   \n",
       "589        -1.046809         0.817773                  0                1   \n",
       "7507       -1.046809         0.329403                  1                0   \n",
       "1457        0.955284        -0.617269                  0                0   \n",
       "\n",
       "      Gender_Male  \n",
       "9716            1  \n",
       "224             1  \n",
       "589             0  \n",
       "7507            1  \n",
       "1457            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# numeric features in dataset\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', \n",
    "           'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "# features scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "# transform the training set and the test set using transform()\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_test[numeric]  = scaler.transform(features_test[numeric])\n",
    "    \n",
    "print(\"\\033[1m\" + 'Shape of features and target' + \"\\033[0m\")\n",
    "print('-'*30)\n",
    "print('Train features :', features_train.shape)\n",
    "print('Train target   :',target_train.shape)\n",
    "print('Test features  :',features_test.shape)\n",
    "print('Test target    :',target_test.shape)\n",
    "print()\n",
    "display(features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "- We’ve used OHE One-Hot-Encoding for changing the categorical features to numerical ones.\n",
    "- Allowing all the added features of each data type (for example both male and female columns to remain) can damage our predictions outcome, and we can fall into the dummy trap because of their high correlation. \n",
    "- To avoid this, we can remove one feature of each data type, and this will not impact on the predictions since we can inferre to one from the other, if one is 0 the other is 1, and so one. \n",
    "- We split the data into 70% training set, and 30% testing sets.\n",
    "- We standardized the numerical features of the data, since the features have different scales.\n",
    "- The resulting dataset now is:\n",
    "    - 7000 rows and 11 columns for the train features set\n",
    "    - 3000 rows and 11 columns for the test features set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> Great that scaler was trained only on train set. It helps to reduce overfitting.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"2\">Examine the balance of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd5b255d6d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['Exited'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, let's look at the class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2037\n",
      "7963\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Exited'] == 1]['Exited'].count())\n",
    "print(df[df['Exited'] == 0]['Exited'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clearly we can the significant imbalance problem\n",
    "- let's check how it will impact our model\n",
    "\n",
    "Let's first calculate the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_evaluation(y_test, test_predictions):\n",
    "    print(\"\\033[1m\" + 'F1 score: ' + \"\\033[0m\", '{:.3f}'.format(f1_score(y_test, test_predictions)))\n",
    "    print(\"\\033[1m\" + 'Accuracy Score: ' + \"\\033[0m\", '{:.2%}'.format(accuracy_score(y_test, test_predictions)))\n",
    "    print(\"\\033[1m\" + 'Precision: ' + \"\\033[0m\", '{:.3f}'.format(precision_score(y_test, test_predictions)))\n",
    "    print(\"\\033[1m\" + 'Recall: ' + \"\\033[0m\", '{:.3f}'.format(recall_score(y_test, test_predictions)))\n",
    "    print(\"\\033[1m\" + 'Balanced Accuracy Score: ' + \"\\033[0m\", '{:.2%}'.format(balanced_accuracy_score(y_test, test_predictions)))\n",
    "    print(\"\\033[1m\" + 'ROC AUC Score: ' + \"\\033[0m\", '{:.2%}'.format(roc_auc_score(y_test, test_predictions)))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'Confusion Matrix' + \"\\033[0m\")\n",
    "    print('-'*50)\n",
    "    print(confusion_matrix(y_test, test_predictions))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'Classification report' + \"\\033[0m\")\n",
    "    print('-'*50)\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Model using a dummy classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "dummy_clf_test_predictions = dummy_clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mF1 score: \u001b[0m 0.000\n",
      "\u001b[1mAccuracy Score: \u001b[0m 79.13%\n",
      "\u001b[1mPrecision: \u001b[0m 0.000\n",
      "\u001b[1mRecall: \u001b[0m 0.000\n",
      "\u001b[1mBalanced Accuracy Score: \u001b[0m 50.00%\n",
      "\u001b[1mROC AUC Score: \u001b[0m 50.00%\n",
      "\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "--------------------------------------------------\n",
      "[[2374    0]\n",
      " [ 626    0]]\n",
      "\n",
      "\u001b[1mClassification report\u001b[0m\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      2374\n",
      "           1       0.00      0.00      0.00       626\n",
      "\n",
      "    accuracy                           0.79      3000\n",
      "   macro avg       0.40      0.50      0.44      3000\n",
      "weighted avg       0.63      0.79      0.70      3000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline model\n",
    "print_model_evaluation(target_test, dummy_clf_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The baseline model predicts the most frequent class which is \"0\" in our case. \n",
    "- Looking at this report, we see that:\n",
    "    - the accuracy is high \n",
    "    - but the F1 score is 0.0. \n",
    "- This goes to class imbalance. Which is showing that accuracy alone is not sufficient to evaluate the model’s performance.\n",
    "\n",
    "We then examine the balance of classes and train the model without taking into account the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the logistic regression model\n",
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is a logistic regression model function developed to train\n",
    "    the model, make prediction on train and test dataset, print\n",
    "    model accuracy for training and testing datasets\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    train_predictions = model.predict(X_train) # make predictions on train set\n",
    "    test_predictions = model.predict(X_test) # make prediction on test set\n",
    "    print('F1 score for logistic regression model')\n",
    "    print('-'*35)\n",
    "    print('F1 score: {:.3f}'.format(f1_score(y_test, test_predictions)))\n",
    "    print()\n",
    "    print('The default F1-score of the logistic regression model is ' \"\\033[1m\" + \n",
    "          '{:.3f}.'.format(f1_score(y_test, test_predictions)) + \"\\033[0m\" +\n",
    "          ' The accuracy measured {:.3f}'.format(accuracy_score(y_train, train_predictions)) +\n",
    "          ' for training set and {:.3f}'.format(accuracy_score(y_test, test_predictions)) + ' for the testing set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for logistic regression model\n",
      "-----------------------------------\n",
      "F1 score: 0.302\n",
      "\n",
      "The default F1-score of the logistic regression model is \u001b[1m0.302.\u001b[0m The accuracy measured 0.815 for training set and 0.801 for the testing set.\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for logistic regression model\n",
    "logistic_regression(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.924\n",
      "1    0.076\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train) # train the model \n",
    "test_predictions = pd.Series(model.predict(features_test))\n",
    "class_frequency = test_predictions.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "- In this section, we trained the model pretending that we don't know anything about class imbalance.\n",
    "- We achieved an F1 score of 0.303. \n",
    "- We assess the sanity of the model by checking how often the target feature contains the class \"1\" or \"0\".\n",
    "- We can see the class imbalance in the predicted testing set.\n",
    "\n",
    "We will now try to improve the quality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> This part was done well!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"3\">Improve the quality of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 2 approaches to improve the quality of the model:\n",
    "- Class weight adjustment\n",
    "- Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Weight Adjustment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with adjusted class weight: 0.493\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, class_weight='balanced', solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "test_predictions = model.predict(features_test) \n",
    "print('F1 score with adjusted class weight: {:.3f}'.format(f1_score(target_test, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.620333\n",
      "1    0.379667\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check after class imbalance\n",
    "test_predictions = pd.Series(model.predict(features_test))\n",
    "class_frequency = test_predictions.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By modifying the class_weight='balanced', we can notice how the F1 score increased to 0.493."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upsampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform upsampling \n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# new training set created\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score after upsampling: 0.484\n"
     ]
    }
   ],
   "source": [
    "# F1 score after upsampling \n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "test_predictions = model.predict(features_test) \n",
    "print('F1 score after upsampling: {:.3f}'.format(f1_score(target_test, test_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the upsampling part, we first split the training sample into negative and positive observations, duplicated the positive observations and combine them with the negative class observation. \n",
    "- Then we shuffled the data using shuffle() function, and trained our LogisticRegression model with the new data. \n",
    "- We calculated the F1 score = 0.484. \n",
    "- We went from an F1 score of 0.303 to F1 score = 0.484 which is an improvement when the class is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> Right that upsampling was applied only to train set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"3\">Improve the quality of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot ROC curve\n",
    "def plot_roc(y_test, preds, ax=None, label='model'):\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        \"\"\"\n",
    "        This function plots the ROC curve\n",
    "        \"\"\"\n",
    "        if not ax: fig, ax = plt.subplots(1, 1)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "        ax.plot([0, 1], [0, 1],'r--')\n",
    "        ax.plot(fpr, tpr, lw=2, label=label)\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_title(\n",
    "            'ROC curve\\n'\n",
    "            f\"\"\" AP: {average_precision_score(\n",
    "                y_test, preds, pos_label=1\n",
    "            ):.2} | \"\"\"\n",
    "            f'AUC: {auc(fpr, tpr):.2}'\n",
    "        )\n",
    "        ax.set_xlabel('False Positive Rate (FPR)')\n",
    "        ax.set_ylabel('True Positive Rate (TPR)')\n",
    "        ax.annotate(f'AUC: {auc(fpr, tpr):.2}', xy=(.43, .025))\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        return ax\n",
    "    \n",
    "# function to plot the precision-recall curve\n",
    "def plot_pr(y_test, preds, ax=None, label='model'):\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        \"\"\"\n",
    "        This function is used to the precision-recall curve \n",
    "        \"\"\"\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "        if not ax: fig, ax = plt.subplots()\n",
    "        ax.plot([0, 1], [1, 0],'r--')    \n",
    "        ax.plot(recall, precision, lw=2, label=label)\n",
    "        ax.legend()\n",
    "        ax.set_title(\n",
    "            'Precision-recall curve\\n'\n",
    "            f\"\"\" AP: {average_precision_score(\n",
    "                y_test, preds, pos_label=1\n",
    "            ):.2} | \"\"\"\n",
    "            f'AUC: {auc(recall, precision):.2}'\n",
    "        )\n",
    "        ax.set_xlabel('Recall')\n",
    "        ax.set_ylabel('Precision')\n",
    "        ax.set_xlim(-0.05, 1.05)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "We are going to try and tune the hyperparameters of the following classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We iterate over different values and compare the quality of the model by tuning `max_depth` hyperparameter. \n",
    "- In `GridSearchCV`, we pass scoring='f1' to tune the target metric which is the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters combination that would give best F1 score is : \n",
      "{'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 16}\n",
      "The best accuracy achieved after parameter tuning via grid search is: 0.555\n",
      "The accuracy of the model against the training data is: 0.632\n",
      "F1 score:  0.5369261477045908\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization for Decision tree classifier\n",
    "parameters = {\n",
    "    \"criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"max_depth\" : [2, 4, 8, 16],\n",
    "    \"min_samples_split\" : [2, 4, 8, 16],\n",
    "    \"min_samples_leaf\" : [2, 4, 6]\n",
    "    }\n",
    "classifier = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(classifier, parameters, scoring='f1', cv=5)\n",
    "grid.fit(features_train, target_train) \n",
    "y_pred = grid.predict(features_test)\n",
    "print('The parameters combination that would give best F1 score is : ')\n",
    "print(grid.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid.best_score_))\n",
    "print('The accuracy of the model against the training data is: {:.3f}'.format(grid.score(features_train, target_train)))\n",
    "print('F1 score: ', f1_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> Glad to see that our target metric was specified in \"scoring\" parameter.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the decision tree classifier\n",
    "def decision_tree_classifier(X_train, y_train, X_test, y_test):\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    f1_scores = []\n",
    "    model = DecisionTreeClassifier(**grid.best_params_) \n",
    "    model.fit(X_train, y_train) # train the model\n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on testing set\n",
    "    dt_test_predictions = model.predict(X_test) \n",
    "    dt_test_predictions_acc = accuracy_score(y_test, dt_test_predictions)\n",
    "    test_scores.append(dt_test_predictions_acc)\n",
    "    f1_score_ = f1_score(y_test, dt_test_predictions)\n",
    "    f1_scores.append(f1_score_)\n",
    "    scores = list(zip(f1_scores, train_scores, test_scores))\n",
    "    print('The decision tree classifier had the best ' \"\\033[1m\" + 'F1 score of {:.3f}'.format(max(scores, key = lambda x: x[0])[0]) + \"\\033[0m\" +   \n",
    "          ' and accuracy of ' \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[0])[1]) + ' for the training set' + \"\\033[0m\" + \n",
    "          ' and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[0])[2]) + ' for the testing set' + \"\\033[0m\")\n",
    "    print()\n",
    "    # evaluate decision tree classifier metric\n",
    "    print_model_evaluation(target_test, dt_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree classifier had the best \u001b[1mF1 score of 0.542\u001b[0m and accuracy of \u001b[1m87.90% for the training set\u001b[0m and \u001b[1m84.60% for the testing set\u001b[0m\n",
      "\n",
      "\u001b[1mF1 score: \u001b[0m 0.542\n",
      "\u001b[1mAccuracy Score: \u001b[0m 84.60%\n",
      "\u001b[1mPrecision: \u001b[0m 0.715\n",
      "\u001b[1mRecall: \u001b[0m 0.436\n",
      "\u001b[1mBalanced Accuracy Score: \u001b[0m 69.51%\n",
      "\u001b[1mROC AUC Score: \u001b[0m 69.51%\n",
      "\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "--------------------------------------------------\n",
      "[[2265  109]\n",
      " [ 353  273]]\n",
      "\n",
      "\u001b[1mClassification report\u001b[0m\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      2374\n",
      "           1       0.71      0.44      0.54       626\n",
      "\n",
      "    accuracy                           0.85      3000\n",
      "   macro avg       0.79      0.70      0.72      3000\n",
      "weighted avg       0.83      0.85      0.83      3000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine F1 score for decision tree classifier\n",
    "decision_tree_classifier(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We used `GridSearchCV` for the hyperparameter optimization on the max_depth, criterion, min_samples_split, and min_samples_leaf parameters. \n",
    "- Since we are looking for the best parameter setting for our decision tree classifier. We note that shallow decision trees (e.g. few depth) generally do not overfit but have poor performance (high bias, low variance), and deep trees (e.g. high depth) generally do overfit and have good performance (low bias, high variance). \n",
    "- Our desirable tree depth is one that is not so shallow that it has low performance and not so deep that it overfits the training dataset. We need to have a balance between bias and variance - bias variance tradeoff. \n",
    "- At max_depth of 8, we have an F1 score of 0.54, an accuracy of 87.90% for the training set, and 84.50% for the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters combination that would give best F1 score is : \n",
      "{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "The best accuracy achieved after parameter tuning via grid search is: 0.327\n",
      "The accuracy of the model against the training data is: 0.328\n",
      "F1 score:  0.30069930069930073\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization\n",
    "# define parameters\n",
    "grid = {\n",
    "    \"solver\" : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    \"penalty\" : ['l2'],\n",
    "    \"C\" : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "# define grid search\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the model\n",
    "regressor = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = regressor, param_grid = grid, \n",
    "                           n_jobs=-1, cv=cv, scoring='f1', error_score=0)\n",
    "grid_search.fit(features_train, target_train) \n",
    "y_pred = grid_search.predict(features_test)\n",
    "print('The parameters combination that would give best F1 score is : ')\n",
    "print(grid_search.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid_search.best_score_))\n",
    "print('The accuracy of the model against the training data is: {:.3f}'.format(grid_search.score(features_train, target_train)))\n",
    "print('F1 score: ', f1_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the logistic regression model\n",
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is a logistic regression model function developed to train\n",
    "    the model, make prediction on train and testing dataset, \n",
    "    and print F1 score and evaluation metrics for testing datasets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    f1_scores = []\n",
    "    model = LogisticRegression(**grid_search.best_params_)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on testing set\n",
    "    lr_test_predictions = model.predict(X_test) \n",
    "    lr_test_predictions_acc = accuracy_score(y_test, lr_test_predictions)\n",
    "    test_scores.append(lr_test_predictions_acc)\n",
    "    f1_score_ = f1_score(y_test, lr_test_predictions)\n",
    "    f1_scores.append(f1_score_)\n",
    "    scores = list(zip(f1_scores, train_scores, test_scores))\n",
    "    print('The logistic regression classifier had the best ' \"\\033[1m\" + \n",
    "          'F1 score of {:.3f} '.format(max(scores, key = lambda x: x[0])[0]) + \"\\033[0m\" + \n",
    "          'using' \"\\033[1m\" + ' C parameter of {},'.format(grid_search.best_params_['C']) + \"\\033[0m\" +\n",
    "          \"\\033[1m\" + ' {} as logistic regression solver'.format(grid_search.best_params_['solver']) + \"\\033[0m\" +\n",
    "          ' leading to an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[0])[1]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[0])[2]) + ' for the testing set' + \"\\033[0m\")\n",
    "    print()\n",
    "    # evaluate logistic regression classifier metric\n",
    "    print_model_evaluation(target_test, lr_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The logistic regression classifier had the best \u001b[1mF1 score of 0.301 \u001b[0musing\u001b[1m C parameter of 10,\u001b[0m\u001b[1m liblinear as logistic regression solver\u001b[0m leading to an accuracy of \u001b[1m81.49% for the training set \u001b[0mand \u001b[1m80.00% for the testing set\u001b[0m\n",
      "\n",
      "\u001b[1mF1 score: \u001b[0m 0.301\n",
      "\u001b[1mAccuracy Score: \u001b[0m 80.00%\n",
      "\u001b[1mPrecision: \u001b[0m 0.556\n",
      "\u001b[1mRecall: \u001b[0m 0.206\n",
      "\u001b[1mBalanced Accuracy Score: \u001b[0m 58.13%\n",
      "\u001b[1mROC AUC Score: \u001b[0m 58.13%\n",
      "\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "--------------------------------------------------\n",
      "[[2271  103]\n",
      " [ 497  129]]\n",
      "\n",
      "\u001b[1mClassification report\u001b[0m\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88      2374\n",
      "           1       0.56      0.21      0.30       626\n",
      "\n",
      "    accuracy                           0.80      3000\n",
      "   macro avg       0.69      0.58      0.59      3000\n",
      "weighted avg       0.77      0.80      0.76      3000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine F1 score for logistic regression model\n",
    "logistic_regression(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We tuned the \"C\" parameter for the logistic regression model. \n",
    "- the F1 score is low at 0.297\n",
    "- The logistic regression model gave an accuracy of 81.56 % for the training set, and 80% for the testing sets when using a \"C\" parameter of 10. \n",
    "- We can see here that neither the training nor the testing score is high enough. This is because the model is not complex enough and underfitting may occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters combination that would give best F1 score is : \n",
      "{'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 50}\n",
      "The best accuracy achieved after parameter tuning via grid search is: 0.576\n",
      "The accuracy of the model against the training data is: 0.742\n",
      "F1 score:  0.5567010309278351\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization for Random Forest classifier\n",
    "# define the hyperparameter to tune\n",
    "parameters = {\n",
    "    \"criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\" : [10, 50],\n",
    "    \"max_depth\" : [None, 2, 4, 8, 10, 12],\n",
    "    \"min_samples_split\" : [2, 4, 8, 16],\n",
    "    \"min_samples_leaf\" : [2, 4, 6]\n",
    "    }\n",
    "# define the model with default hyperparameters\n",
    "classifier = RandomForestClassifier()\n",
    "# define the grid search procedure\n",
    "grid_rf = GridSearchCV(estimator=classifier, param_grid=parameters, \n",
    "                    cv=5, scoring='f1')\n",
    "# execute the grid search\n",
    "grid_rf.fit(features_train, target_train) \n",
    "y_pred = grid_rf.predict(features_test)\n",
    "print('The parameters combination that would give best F1 score is : ')\n",
    "print(grid_rf.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid_rf.best_score_))\n",
    "print('The accuracy of the model against the training data is: {:.3f}'.format(grid_rf.score(features_train, target_train)))\n",
    "print('F1 score: ', f1_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random forest classifier model\n",
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is a random forest classifier function developed to train\n",
    "    the model, make prediction on train and testing dataset, \n",
    "    and print F1 score and evaluation metrics for testing datasets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    f1_scores = []\n",
    "    model = RandomForestClassifier(**grid_rf.best_params_)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on testing set\n",
    "    rf_test_predictions = model.predict(X_test) \n",
    "    rf_test_predictions_acc = accuracy_score(y_test, rf_test_predictions)\n",
    "    test_scores.append(rf_test_predictions_acc)\n",
    "    f1_score_ = f1_score(y_test, rf_test_predictions)\n",
    "    f1_scores.append(f1_score_)\n",
    "    scores = list(zip(f1_scores, train_scores, test_scores))\n",
    "    print('The random forest classifier had the best ' \"\\033[1m\" + \n",
    "          'F1 score of {:.3f} '.format(max(scores, key = lambda x: x[0])[0]) + \"\\033[0m\" + \n",
    "          'using' \"\\033[1m\" + ' n_estimate value of {},'.format(grid_rf.best_params_['n_estimators']) + \"\\033[0m\" +\n",
    "          \"\\033[1m\" + ' maximum tree depth of {}'.format(grid_rf.best_params_['max_depth']) + \"\\033[0m\" +\n",
    "          ' giving an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[0])[1]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[0])[2]) + ' for the test set' + \"\\033[0m\")\n",
    "    print()\n",
    "    # evaluate random forest classifier metric\n",
    "    print_model_evaluation(target_test, rf_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random forest classifier had the best \u001b[1mF1 score of 0.555 \u001b[0musing\u001b[1m n_estimate value of 50,\u001b[0m\u001b[1m maximum tree depth of None\u001b[0m giving an accuracy of \u001b[1m91.40% for the training set \u001b[0mand \u001b[1m85.47% for the test set\u001b[0m\n",
      "\n",
      "\u001b[1mF1 score: \u001b[0m 0.555\n",
      "\u001b[1mAccuracy Score: \u001b[0m 85.47%\n",
      "\u001b[1mPrecision: \u001b[0m 0.768\n",
      "\u001b[1mRecall: \u001b[0m 0.435\n",
      "\u001b[1mBalanced Accuracy Score: \u001b[0m 70.00%\n",
      "\u001b[1mROC AUC Score: \u001b[0m 70.00%\n",
      "\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "--------------------------------------------------\n",
      "[[2292   82]\n",
      " [ 354  272]]\n",
      "\n",
      "\u001b[1mClassification report\u001b[0m\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.91      2374\n",
      "           1       0.77      0.43      0.56       626\n",
      "\n",
      "    accuracy                           0.85      3000\n",
      "   macro avg       0.82      0.70      0.73      3000\n",
      "weighted avg       0.85      0.85      0.84      3000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for random forest classifier\n",
    "random_forest_classifier(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Random Forest classifier resulting in an F1 score of 0.55, accuracy of 96.39% for the training set, and 85.33% for the testing sets when using an n_estimate value of 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the CatBoost classifier model\n",
    "def catboost_classifier(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is a catboost classifier function developed to train\n",
    "    the model, make prediction on train and testing dataset, \n",
    "    and print F1 score and evaluation metrics for testing datasets\n",
    "    \"\"\"\n",
    "    # define model\n",
    "    model = CatBoostClassifier(verbose=0, random_state=12345)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    # make predictions on testing set\n",
    "    cb_test_predictions = model.predict(X_test) \n",
    "    cb_test_predictions_acc = accuracy_score(y_test, cb_test_predictions)\n",
    "    f1_score_ = f1_score(y_test, cb_test_predictions)\n",
    "    print('The model has an ' \"\\033[1m\" 'F1 score of {:.3f},'.format(f1_score_) + \"\\033[0m\" +\n",
    "          ' accuracy of ' \"\\033[1m\" + '{:.2%}'.format(train_predictions_acc) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(cb_test_predictions_acc) + ' for the testing set' + \"\\033[0m\")\n",
    "    print()\n",
    "    # evaluate catboost classifier metric\n",
    "    print_model_evaluation(target_test, cb_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has an \u001b[1mF1 score of 0.588,\u001b[0m accuracy of \u001b[1m92.17% for the training set \u001b[0mand \u001b[1m85.87% for the testing set\u001b[0m\n",
      "\n",
      "\u001b[1mF1 score: \u001b[0m 0.588\n",
      "\u001b[1mAccuracy Score: \u001b[0m 85.87%\n",
      "\u001b[1mPrecision: \u001b[0m 0.751\n",
      "\u001b[1mRecall: \u001b[0m 0.482\n",
      "\u001b[1mBalanced Accuracy Score: \u001b[0m 72.02%\n",
      "\u001b[1mROC AUC Score: \u001b[0m 72.02%\n",
      "\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "--------------------------------------------------\n",
      "[[2274  100]\n",
      " [ 324  302]]\n",
      "\n",
      "\u001b[1mClassification report\u001b[0m\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91      2374\n",
      "           1       0.75      0.48      0.59       626\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.81      0.72      0.75      3000\n",
      "weighted avg       0.85      0.86      0.85      3000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine F1 score for CatBoost algorithm\n",
    "catboost_classifier(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "- After checking different model quality, we can understand that the CatBoost classifier gives the best result for F1 score of 0.587, accuracy of 85.83% and AUC-ROC value of 71.99% , from the 4 different models investigated. \n",
    "- The logistic regression model had the lowest values for F1 score of 0.297, accuracy of 81.56%, and AUC-ROC of 58.04%. \n",
    "- The Catboost model is the best model based on the F1 score when predicting whether a customer will leave the bank soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> Great that you've tried a lot of different models!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Improve: </b> It would be better if you've made experiments with different methods of fixing class balancing for all models.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"4\">Perform the final testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After the model quality investigation we've seen that CatBoost classifier is maybe the most accurate model. Using the CatBoost classifier as our final model, we can make predictions using the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the CatBoost classifier model\n",
    "def catboost_classifier(X_train, y_train, X_test, y_test):\n",
    "    # define model\n",
    "    model = CatBoostClassifier(verbose=0, random_state=12345)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    # make predictions on test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_predictions_acc = accuracy_score(y_test, test_predictions)\n",
    "    f1_score_ = f1_score(y_test, test_predictions)\n",
    "    print('The model has an ' \"\\033[1m\" 'F1 score of {:.3f},'.format(f1_score_) + \"\\033[0m\" +\n",
    "          ' accuracy of ' \"\\033[1m\" + '{:.2%}'.format(train_predictions_acc) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(test_predictions_acc) + ' for the test set' + \"\\033[0m\")\n",
    "    # plot of ROC and Precision-Recall curve\n",
    "    test_predict = model.predict_proba(X_test)\n",
    "    test_predictions_one = test_predict[:,1]\n",
    "    auc_roc = roc_auc_score(y_test, test_predictions_one)\n",
    "    print('Area under the ROC Curve: {}'.format(auc_roc))\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, test_predictions_one)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict(X_test))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has an \u001b[1mF1 score of 0.588,\u001b[0m accuracy of \u001b[1m92.17% for the training set \u001b[0mand \u001b[1m85.87% for the test set\u001b[0m\n",
      "Area under the ROC Curve: 0.8607969456115372\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CatBoost classifier + pr/roc curve\n",
    "catboost_classifier(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a `catboost_classifier`, we obtained an F1 score of 0.58, accuracy of 92.17% for the training set and 85.87% for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<b>Needs fixing:</b> Please use `predict_proba` instead of `predict` while visualizing curves: https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python .\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"4\">Overall conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business task of this project is to predict customers’ bank churn, to do so we went through the following steps:\n",
    "- In the first part , we downloaded and prepared the data. The data contained 10000 rows and 14 features. We’ve notice that 9.9% of the data is missing in the `Tenure` column, and the data is missing at random (MAR). \n",
    "- We replaced the missing values, changed the datatype, and encoded the categorical feature using one-hot encoding. We splitted the data into 70% training set, and 30% testing sets. \n",
    "- We’ve also standardized the numerical features of the data. \n",
    "- The size of the new table is 7000 rows and 11 columns for the train features set, and 3000 rows and 11 columns for the test features set.\n",
    "- We trained the model without taking into account the imbalance. Achieving an F1 score of 0.303. \n",
    "- We assess the sanity of the model and observed the class imbalance in the dataset( the 0 much more than the 1).\n",
    "- We improved the quality of the model using two approaches to fixing class imbalance. \n",
    "    - We first split the training sample into negative and positive observations, we duplicated the positive observations and combined them with the negative class observation. Then we shuffled the data using shuffle() function, and trained our LogisticRegression model with the new data. We calculated the F1 score to be 0.494\n",
    "- We investigated several models and tuned different hyperparameters for those models\n",
    "- From our investigation, we’ve seen that the CatBoost classifier gave 92.11% for the training set and 85.83% for the testing set, which is the best result compared to the other models. \n",
    "- In the final test prediction on the test data, we used the CatBoost classifier and  obtained an F1-score of 0.587.\n",
    "- We’ve responded to the business task of this project which is to predict whether a customer will leave the bank soon with an accuracy of 85.83% and an F1-score of 0.587. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> Glad to see well-structured conclusion at the end of the project!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 89,
    "start_time": "2021-08-03T20:59:32.357Z"
   },
   {
    "duration": 1155,
    "start_time": "2021-08-03T22:07:38.914Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-03T22:08:05.791Z"
   },
   {
    "duration": 148,
    "start_time": "2021-08-03T22:08:30.330Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-03T22:08:48.658Z"
   },
   {
    "duration": 97,
    "start_time": "2021-08-03T22:14:12.668Z"
   },
   {
    "duration": 13737,
    "start_time": "2021-08-03T22:54:22.804Z"
   },
   {
    "duration": 39,
    "start_time": "2021-08-03T22:54:36.542Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T00:18:34.258Z"
   },
   {
    "duration": 15,
    "start_time": "2021-08-04T00:24:52.637Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T00:58:21.234Z"
   },
   {
    "duration": 11,
    "start_time": "2021-08-04T01:00:08.487Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-04T01:00:49.166Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T01:01:05.220Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T01:01:49.649Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T01:02:13.410Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T01:02:35.311Z"
   },
   {
    "duration": 35,
    "start_time": "2021-08-04T01:03:04.833Z"
   },
   {
    "duration": 1076,
    "start_time": "2021-08-04T01:09:22.384Z"
   },
   {
    "duration": 167,
    "start_time": "2021-08-04T01:09:23.462Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T01:09:23.630Z"
   },
   {
    "duration": 107,
    "start_time": "2021-08-04T01:09:23.639Z"
   },
   {
    "duration": 12901,
    "start_time": "2021-08-04T01:09:23.747Z"
   },
   {
    "duration": 35,
    "start_time": "2021-08-04T01:09:36.650Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T01:09:36.687Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T01:09:36.696Z"
   },
   {
    "duration": 37,
    "start_time": "2021-08-04T01:09:36.708Z"
   },
   {
    "duration": 11,
    "start_time": "2021-08-04T01:09:36.747Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T01:09:36.760Z"
   },
   {
    "duration": 11,
    "start_time": "2021-08-04T01:09:36.767Z"
   },
   {
    "duration": 14,
    "start_time": "2021-08-04T01:09:36.780Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T01:09:36.795Z"
   },
   {
    "duration": 40,
    "start_time": "2021-08-04T01:09:36.802Z"
   },
   {
    "duration": 34,
    "start_time": "2021-08-04T01:09:36.844Z"
   },
   {
    "duration": 342,
    "start_time": "2021-08-04T01:26:23.252Z"
   },
   {
    "duration": 57,
    "start_time": "2021-08-04T01:27:10.094Z"
   },
   {
    "duration": 305,
    "start_time": "2021-08-04T01:27:21.177Z"
   },
   {
    "duration": 131,
    "start_time": "2021-08-04T01:27:28.382Z"
   },
   {
    "duration": 3382,
    "start_time": "2021-08-04T01:27:38.586Z"
   },
   {
    "duration": 135,
    "start_time": "2021-08-04T01:27:45.138Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T01:36:12.659Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T01:40:10.226Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-04T02:23:42.424Z"
   },
   {
    "duration": 23,
    "start_time": "2021-08-04T02:24:04.278Z"
   },
   {
    "duration": 1187,
    "start_time": "2021-08-04T02:25:33.850Z"
   },
   {
    "duration": 194,
    "start_time": "2021-08-04T02:25:35.039Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T02:25:35.234Z"
   },
   {
    "duration": 106,
    "start_time": "2021-08-04T02:25:35.243Z"
   },
   {
    "duration": 12594,
    "start_time": "2021-08-04T02:25:35.350Z"
   },
   {
    "duration": 35,
    "start_time": "2021-08-04T02:25:47.946Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T02:25:47.982Z"
   },
   {
    "duration": 11,
    "start_time": "2021-08-04T02:25:47.992Z"
   },
   {
    "duration": 37,
    "start_time": "2021-08-04T02:25:48.005Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T02:25:48.044Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T02:25:48.058Z"
   },
   {
    "duration": 17,
    "start_time": "2021-08-04T02:25:48.068Z"
   },
   {
    "duration": 13,
    "start_time": "2021-08-04T02:25:48.087Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T02:25:48.102Z"
   },
   {
    "duration": 33,
    "start_time": "2021-08-04T02:25:48.110Z"
   },
   {
    "duration": 33,
    "start_time": "2021-08-04T02:25:48.144Z"
   },
   {
    "duration": 149,
    "start_time": "2021-08-04T02:25:48.178Z"
   },
   {
    "duration": 15,
    "start_time": "2021-08-04T02:25:48.328Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T02:25:48.345Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T02:25:48.351Z"
   },
   {
    "duration": 28,
    "start_time": "2021-08-04T02:25:48.359Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-04T02:31:25.732Z"
   },
   {
    "duration": 86,
    "start_time": "2021-08-04T02:31:44.458Z"
   },
   {
    "duration": 333,
    "start_time": "2021-08-04T02:32:08.415Z"
   },
   {
    "duration": 1295,
    "start_time": "2021-08-04T02:32:39.331Z"
   },
   {
    "duration": 86,
    "start_time": "2021-08-04T02:32:40.628Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T02:32:40.716Z"
   },
   {
    "duration": 92,
    "start_time": "2021-08-04T02:32:40.724Z"
   },
   {
    "duration": 12755,
    "start_time": "2021-08-04T02:32:40.817Z"
   },
   {
    "duration": 36,
    "start_time": "2021-08-04T02:32:53.574Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T02:32:53.612Z"
   },
   {
    "duration": 29,
    "start_time": "2021-08-04T02:32:53.622Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T02:32:53.653Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T02:32:53.663Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T02:32:53.676Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T02:32:53.683Z"
   },
   {
    "duration": 46,
    "start_time": "2021-08-04T02:32:53.695Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T02:32:53.743Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T02:32:53.752Z"
   },
   {
    "duration": 34,
    "start_time": "2021-08-04T02:32:53.760Z"
   },
   {
    "duration": 158,
    "start_time": "2021-08-04T02:32:53.795Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T02:32:53.954Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T02:32:53.963Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T02:32:53.970Z"
   },
   {
    "duration": 25,
    "start_time": "2021-08-04T02:32:53.977Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-04T02:32:54.004Z"
   },
   {
    "duration": 132,
    "start_time": "2021-08-04T02:32:54.010Z"
   },
   {
    "duration": 404,
    "start_time": "2021-08-04T02:32:54.144Z"
   },
   {
    "duration": 21,
    "start_time": "2021-08-04T02:39:21.441Z"
   },
   {
    "duration": 307,
    "start_time": "2021-08-04T02:39:44.442Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T02:43:11.100Z"
   },
   {
    "duration": 31,
    "start_time": "2021-08-04T02:43:25.960Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T02:48:35.506Z"
   },
   {
    "duration": 8138,
    "start_time": "2021-08-04T02:54:51.254Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T02:55:41.664Z"
   },
   {
    "duration": 53,
    "start_time": "2021-08-04T02:55:59.101Z"
   },
   {
    "duration": 1206,
    "start_time": "2021-08-04T03:05:06.319Z"
   },
   {
    "duration": 80,
    "start_time": "2021-08-04T03:05:07.527Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T03:05:07.609Z"
   },
   {
    "duration": 89,
    "start_time": "2021-08-04T03:05:07.617Z"
   },
   {
    "duration": 12755,
    "start_time": "2021-08-04T03:05:07.708Z"
   },
   {
    "duration": 36,
    "start_time": "2021-08-04T03:05:20.465Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T03:05:20.503Z"
   },
   {
    "duration": 32,
    "start_time": "2021-08-04T03:05:20.511Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T03:05:20.545Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T03:05:20.555Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T03:05:20.567Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T03:05:20.574Z"
   },
   {
    "duration": 14,
    "start_time": "2021-08-04T03:05:20.588Z"
   },
   {
    "duration": 37,
    "start_time": "2021-08-04T03:05:20.604Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T03:05:20.643Z"
   },
   {
    "duration": 33,
    "start_time": "2021-08-04T03:05:20.652Z"
   },
   {
    "duration": 156,
    "start_time": "2021-08-04T03:05:20.686Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T03:05:20.844Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T03:05:20.854Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T03:05:20.861Z"
   },
   {
    "duration": 26,
    "start_time": "2021-08-04T03:05:20.869Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-04T03:05:20.897Z"
   },
   {
    "duration": 138,
    "start_time": "2021-08-04T03:05:20.905Z"
   },
   {
    "duration": 405,
    "start_time": "2021-08-04T03:05:21.046Z"
   },
   {
    "duration": 24,
    "start_time": "2021-08-04T03:05:21.453Z"
   },
   {
    "duration": 323,
    "start_time": "2021-08-04T03:05:21.542Z"
   },
   {
    "duration": 13,
    "start_time": "2021-08-04T03:05:21.867Z"
   },
   {
    "duration": 61,
    "start_time": "2021-08-04T03:05:21.881Z"
   },
   {
    "duration": 98,
    "start_time": "2021-08-04T03:05:21.944Z"
   },
   {
    "duration": 8125,
    "start_time": "2021-08-04T03:05:22.044Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T03:05:30.170Z"
   },
   {
    "duration": 64,
    "start_time": "2021-08-04T03:05:30.177Z"
   },
   {
    "duration": 129306,
    "start_time": "2021-08-04T03:05:30.243Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T03:08:11.986Z"
   },
   {
    "duration": 514,
    "start_time": "2021-08-04T03:08:25.341Z"
   },
   {
    "duration": 1322,
    "start_time": "2021-08-04T03:19:00.019Z"
   },
   {
    "duration": 86,
    "start_time": "2021-08-04T03:19:01.343Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T03:19:01.431Z"
   },
   {
    "duration": 93,
    "start_time": "2021-08-04T03:19:01.439Z"
   },
   {
    "duration": 12690,
    "start_time": "2021-08-04T03:19:01.533Z"
   },
   {
    "duration": 40,
    "start_time": "2021-08-04T03:19:14.225Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T03:19:14.266Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T03:19:14.274Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T03:19:14.286Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T03:19:14.296Z"
   },
   {
    "duration": 37,
    "start_time": "2021-08-04T03:19:14.308Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T03:19:14.347Z"
   },
   {
    "duration": 14,
    "start_time": "2021-08-04T03:19:14.361Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T03:19:14.376Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T03:19:14.389Z"
   },
   {
    "duration": 46,
    "start_time": "2021-08-04T03:19:14.399Z"
   },
   {
    "duration": 148,
    "start_time": "2021-08-04T03:19:14.446Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T03:19:14.595Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T03:19:14.604Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T03:19:14.611Z"
   },
   {
    "duration": 42,
    "start_time": "2021-08-04T03:19:14.618Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-04T03:19:14.661Z"
   },
   {
    "duration": 80,
    "start_time": "2021-08-04T03:19:14.667Z"
   },
   {
    "duration": 406,
    "start_time": "2021-08-04T03:19:14.749Z"
   },
   {
    "duration": 85,
    "start_time": "2021-08-04T03:19:15.157Z"
   },
   {
    "duration": 316,
    "start_time": "2021-08-04T03:19:15.245Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T03:19:15.564Z"
   },
   {
    "duration": 65,
    "start_time": "2021-08-04T03:19:15.577Z"
   },
   {
    "duration": 98,
    "start_time": "2021-08-04T03:19:15.644Z"
   },
   {
    "duration": 8254,
    "start_time": "2021-08-04T03:19:15.745Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T03:19:24.001Z"
   },
   {
    "duration": 68,
    "start_time": "2021-08-04T03:19:24.008Z"
   },
   {
    "duration": 133665,
    "start_time": "2021-08-04T03:19:24.077Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T03:21:37.744Z"
   },
   {
    "duration": 602,
    "start_time": "2021-08-04T03:21:37.754Z"
   },
   {
    "duration": 1082361,
    "start_time": "2021-08-04T03:21:38.358Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T03:39:59.642Z"
   },
   {
    "duration": 641,
    "start_time": "2021-08-04T03:40:18.456Z"
   },
   {
    "duration": 77,
    "start_time": "2021-08-04T03:41:39.094Z"
   },
   {
    "duration": 21012,
    "start_time": "2021-08-04T03:41:47.091Z"
   },
   {
    "duration": 167687,
    "start_time": "2021-08-04T03:49:51.821Z"
   },
   {
    "duration": 101416,
    "start_time": "2021-08-04T03:52:50.042Z"
   },
   {
    "duration": 188498,
    "start_time": "2021-08-04T03:54:42.154Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T03:57:50.654Z"
   },
   {
    "duration": 20579,
    "start_time": "2021-08-04T03:58:32.268Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T03:59:15.813Z"
   },
   {
    "duration": 463,
    "start_time": "2021-08-04T03:59:34.807Z"
   },
   {
    "duration": 2118,
    "start_time": "2021-08-04T13:45:17.490Z"
   },
   {
    "duration": 126,
    "start_time": "2021-08-04T13:45:19.612Z"
   },
   {
    "duration": 13,
    "start_time": "2021-08-04T13:45:19.742Z"
   },
   {
    "duration": 207,
    "start_time": "2021-08-04T13:45:19.759Z"
   },
   {
    "duration": 25520,
    "start_time": "2021-08-04T13:45:19.970Z"
   },
   {
    "duration": 82,
    "start_time": "2021-08-04T13:45:45.492Z"
   },
   {
    "duration": 11,
    "start_time": "2021-08-04T13:45:45.578Z"
   },
   {
    "duration": 27,
    "start_time": "2021-08-04T13:45:45.593Z"
   },
   {
    "duration": 40,
    "start_time": "2021-08-04T13:45:45.626Z"
   },
   {
    "duration": 28,
    "start_time": "2021-08-04T13:45:45.669Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T13:45:45.708Z"
   },
   {
    "duration": 63,
    "start_time": "2021-08-04T13:45:45.717Z"
   },
   {
    "duration": 22,
    "start_time": "2021-08-04T13:45:45.782Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T13:45:45.807Z"
   },
   {
    "duration": 49,
    "start_time": "2021-08-04T13:45:45.818Z"
   },
   {
    "duration": 96,
    "start_time": "2021-08-04T13:45:45.870Z"
   },
   {
    "duration": 440,
    "start_time": "2021-08-04T13:45:45.970Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T13:45:46.413Z"
   },
   {
    "duration": 32,
    "start_time": "2021-08-04T13:45:46.428Z"
   },
   {
    "duration": 18,
    "start_time": "2021-08-04T13:45:46.463Z"
   },
   {
    "duration": 52,
    "start_time": "2021-08-04T13:45:46.484Z"
   },
   {
    "duration": 20,
    "start_time": "2021-08-04T13:45:46.539Z"
   },
   {
    "duration": 190,
    "start_time": "2021-08-04T13:45:46.566Z"
   },
   {
    "duration": 629,
    "start_time": "2021-08-04T13:45:46.761Z"
   },
   {
    "duration": 70,
    "start_time": "2021-08-04T13:45:47.393Z"
   },
   {
    "duration": 591,
    "start_time": "2021-08-04T13:45:47.466Z"
   },
   {
    "duration": 27,
    "start_time": "2021-08-04T13:45:48.064Z"
   },
   {
    "duration": 96,
    "start_time": "2021-08-04T13:45:48.094Z"
   },
   {
    "duration": 21,
    "start_time": "2021-08-04T13:45:48.254Z"
   },
   {
    "duration": 17660,
    "start_time": "2021-08-04T13:45:48.356Z"
   },
   {
    "duration": 13,
    "start_time": "2021-08-04T13:46:06.019Z"
   },
   {
    "duration": 109,
    "start_time": "2021-08-04T13:46:06.036Z"
   },
   {
    "duration": 342416,
    "start_time": "2021-08-04T13:46:06.147Z"
   },
   {
    "duration": 93,
    "start_time": "2021-08-04T13:51:48.566Z"
   },
   {
    "duration": 223,
    "start_time": "2021-08-04T13:51:48.661Z"
   },
   {
    "duration": 364507,
    "start_time": "2021-08-04T13:51:48.887Z"
   },
   {
    "duration": 15,
    "start_time": "2021-08-04T13:57:53.397Z"
   },
   {
    "duration": 744,
    "start_time": "2021-08-04T13:57:53.415Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T13:57:54.162Z"
   },
   {
    "duration": 46306,
    "start_time": "2021-08-04T13:57:54.180Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T13:58:40.490Z"
   },
   {
    "duration": 45764,
    "start_time": "2021-08-04T13:58:40.502Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T14:35:09.616Z"
   },
   {
    "duration": 37871,
    "start_time": "2021-08-04T14:35:28.922Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T14:37:39.679Z"
   },
   {
    "duration": 40361,
    "start_time": "2021-08-04T14:37:44.857Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T14:39:44.295Z"
   },
   {
    "duration": 43394,
    "start_time": "2021-08-04T14:39:52.903Z"
   },
   {
    "duration": 20,
    "start_time": "2021-08-04T15:16:59.361Z"
   },
   {
    "duration": 285,
    "start_time": "2021-08-04T15:18:15.126Z"
   },
   {
    "duration": 16,
    "start_time": "2021-08-04T15:18:19.300Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T15:18:55.999Z"
   },
   {
    "duration": 329,
    "start_time": "2021-08-04T15:19:30.358Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T15:19:41.841Z"
   },
   {
    "duration": 480,
    "start_time": "2021-08-04T15:20:25.677Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T15:22:52.390Z"
   },
   {
    "duration": 27028,
    "start_time": "2021-08-04T15:23:01.683Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T15:32:52.506Z"
   },
   {
    "duration": 27634,
    "start_time": "2021-08-04T15:32:58.985Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T15:36:36.683Z"
   },
   {
    "duration": 26694,
    "start_time": "2021-08-04T15:36:43.311Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T15:39:36.489Z"
   },
   {
    "duration": 26897,
    "start_time": "2021-08-04T15:39:42.835Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T15:40:47.539Z"
   },
   {
    "duration": 28845,
    "start_time": "2021-08-04T15:40:53.521Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T15:43:32.413Z"
   },
   {
    "duration": 28225,
    "start_time": "2021-08-04T15:43:40.966Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T15:44:58.150Z"
   },
   {
    "duration": 27851,
    "start_time": "2021-08-04T15:45:03.817Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T15:59:10.430Z"
   },
   {
    "duration": 30768,
    "start_time": "2021-08-04T15:59:15.083Z"
   },
   {
    "duration": 13,
    "start_time": "2021-08-04T16:00:48.964Z"
   },
   {
    "duration": 40607,
    "start_time": "2021-08-04T16:00:54.138Z"
   },
   {
    "duration": 121,
    "start_time": "2021-08-04T16:03:51.304Z"
   },
   {
    "duration": 102,
    "start_time": "2021-08-04T16:04:18.270Z"
   },
   {
    "duration": 15,
    "start_time": "2021-08-04T16:25:38.386Z"
   },
   {
    "duration": 32878,
    "start_time": "2021-08-04T16:25:46.055Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T16:36:08.981Z"
   },
   {
    "duration": 28717,
    "start_time": "2021-08-04T16:36:12.635Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T16:44:07.236Z"
   },
   {
    "duration": 28433,
    "start_time": "2021-08-04T16:44:11.217Z"
   },
   {
    "duration": 1571,
    "start_time": "2021-08-04T16:47:21.811Z"
   },
   {
    "duration": 160,
    "start_time": "2021-08-04T16:47:23.385Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T16:47:23.548Z"
   },
   {
    "duration": 174,
    "start_time": "2021-08-04T16:47:23.563Z"
   },
   {
    "duration": 23133,
    "start_time": "2021-08-04T16:47:23.755Z"
   },
   {
    "duration": 70,
    "start_time": "2021-08-04T16:47:46.890Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T16:47:46.962Z"
   },
   {
    "duration": 18,
    "start_time": "2021-08-04T16:47:46.976Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T16:47:46.997Z"
   },
   {
    "duration": 62,
    "start_time": "2021-08-04T16:47:47.011Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T16:47:47.075Z"
   },
   {
    "duration": 18,
    "start_time": "2021-08-04T16:47:47.086Z"
   },
   {
    "duration": 21,
    "start_time": "2021-08-04T16:47:47.106Z"
   },
   {
    "duration": 30,
    "start_time": "2021-08-04T16:47:47.129Z"
   },
   {
    "duration": 20,
    "start_time": "2021-08-04T16:47:47.162Z"
   },
   {
    "duration": 72,
    "start_time": "2021-08-04T16:47:47.184Z"
   },
   {
    "duration": 242,
    "start_time": "2021-08-04T16:47:47.258Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T16:47:47.503Z"
   },
   {
    "duration": 13,
    "start_time": "2021-08-04T16:47:47.515Z"
   },
   {
    "duration": 27,
    "start_time": "2021-08-04T16:47:47.530Z"
   },
   {
    "duration": 53,
    "start_time": "2021-08-04T16:47:47.559Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T16:47:47.614Z"
   },
   {
    "duration": 136,
    "start_time": "2021-08-04T16:47:47.626Z"
   },
   {
    "duration": 401,
    "start_time": "2021-08-04T16:47:47.855Z"
   },
   {
    "duration": 96,
    "start_time": "2021-08-04T16:47:48.259Z"
   },
   {
    "duration": 454,
    "start_time": "2021-08-04T16:47:48.359Z"
   },
   {
    "duration": 16,
    "start_time": "2021-08-04T16:47:48.816Z"
   },
   {
    "duration": 120,
    "start_time": "2021-08-04T16:47:48.835Z"
   },
   {
    "duration": 100,
    "start_time": "2021-08-04T16:47:48.958Z"
   },
   {
    "duration": 13231,
    "start_time": "2021-08-04T16:47:49.061Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T16:48:02.294Z"
   },
   {
    "duration": 88,
    "start_time": "2021-08-04T16:48:02.305Z"
   },
   {
    "duration": 182866,
    "start_time": "2021-08-04T16:48:02.396Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T16:51:05.355Z"
   },
   {
    "duration": 211,
    "start_time": "2021-08-04T16:51:05.367Z"
   },
   {
    "duration": 310515,
    "start_time": "2021-08-04T16:51:05.580Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T16:56:16.098Z"
   },
   {
    "duration": 662,
    "start_time": "2021-08-04T16:56:16.109Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T16:56:16.774Z"
   },
   {
    "duration": 26181,
    "start_time": "2021-08-04T16:56:16.785Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T16:56:42.969Z"
   },
   {
    "duration": 26023,
    "start_time": "2021-08-04T16:56:42.980Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T17:13:22.411Z"
   },
   {
    "duration": 27110,
    "start_time": "2021-08-04T17:13:27.718Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
